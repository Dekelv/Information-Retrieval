{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Syntactic Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_syntactic_features(tweets):\n",
    "    syn_features = [];\n",
    "\n",
    "    for tweet in tweets:\n",
    "        #List of all possible coarse pos-tags. 'Space' pos-tag not included\n",
    "        tagset = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
    "        (pos_list,ents_list) = get_pos_and_ner(tweet)\n",
    "        num_tokens = len(pos_list)\n",
    "        pos_map = Counter([pos for (_,pos,_,_) in pos_list])\n",
    "        \n",
    "        pos_features = []\n",
    "        for tag in tagset:\n",
    "            bin_feat = 1 if pos_map[tag] > 0 else 0\n",
    "            bound_freq_feat = 2 if pos_map[tag] > 1 else pos_map[tag]\n",
    "            unbound_freq_feat = pos_map[tag]\n",
    "            perc_feat = pos_map[tag] / num_tokens\n",
    "            \n",
    "            pos_features.append(bin_feat)\n",
    "            pos_features.append(bound_freq_feat)\n",
    "            pos_features.append(unbound_freq_feat)\n",
    "            pos_features.append(perc_feat)\n",
    "            \n",
    "            \n",
    "        #verb_tenses = [pos for (_,pos,_) in pos_list]]\n",
    "            \n",
    "        num_ents = len(ents_list)\n",
    "        bin_ents = 1 if num_ents > 0 else 0\n",
    "        num_tokens_ents = len([ent_type for (_,_,_,ent_type) in pos_list])\n",
    "        #freq_tokens_ents = no clue\n",
    "            \n",
    "        ent_features = [bin_ents, num_ents, num_tokens_ents]\n",
    "        \n",
    "        syn_features.append(pos_features + ent_features)\n",
    "    \n",
    "    return syn_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature ablation + Experimental setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_df = pd.read_csv('data/training.txt', sep='\\t', quotechar='~')\n",
    "test_df = pd.read_csv('data/test.txt', sep='\\t', quotechar='~')\n",
    "\n",
    "training_true_labels = np.array(training_df['Label'])\n",
    "training_tweets = np.array(training_df['Tweet text'])\n",
    "\n",
    "test_true_labels = np.array(test_df['Label'])\n",
    "test_tweets = np.array(test_df['Tweet text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load features for training and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Semantical_features\n",
    "\n",
    "#train_lex_features =\n",
    "train_syn_features = get_syntactic_features(training_tweets)\n",
    "#train_sen_features =\n",
    "train_sem_feature = get_semantical_features(training_tweets)\n",
    "\n",
    "len(train_syn_features)\n",
    "\n",
    "#test_lex_features =\n",
    "test_syn_features = get_syntactic_features(test_tweets)\n",
    "#test_sen_features =\n",
    "test_sem_feature = get_semantical_features(test_tweets)\n",
    "\n",
    "training_feature_dict = {'Syntactic': train_syn_features}\n",
    "test_feature_dict = {'Syntactic': test_syn_features}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate parameter grid for grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "power = -15\n",
    "gamma_values = list()\n",
    "while power <= 3:\n",
    "    gamma = 2**power\n",
    "    gamma_values.append(gamma)\n",
    "    power += 2 \n",
    " \n",
    "power = -5\n",
    "c_values = list()\n",
    "while power <= 15:\n",
    "    c = 2**power\n",
    "    c_values.append(c)\n",
    "    power += 2\n",
    "    \n",
    "param_grid = {'C': c_values, 'gamma': gamma_values,'kernel': ['rbf']}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy', 'F1-score': 'f1', 'Recall': 'recall', 'Precision': 'precision'}\n",
    "\n",
    "for key in training_feature_dict.keys():\n",
    "    \n",
    "    training_features = training_feature_dict[key]\n",
    "    test_features = test_feature_dict[key]\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, scoring=scoring, refit='Accuracy', verbose=10)\n",
    "    grid.fit(training_features, training_true_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = grid.best_estimator_.predict(test_features)\n",
    "len(predictions)\n",
    "\n",
    "accuracy_score(test_true_labels, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = grid.best_estimator_.predict(test_features)\n",
    "len(predictions)\n",
    "\n",
    "accuracy_score(test_true_labels, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_syntactic_features(tweets):\n",
    "    syn_features = [];\n",
    "\n",
    "    for tweet in tweets:\n",
    "        #List of all possible coarse pos-tags. 'Space' pos-tag not included\n",
    "        tagset = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
    "        (pos_list,ents_list) = get_pos_and_ner(tweet)\n",
    "        num_tokens = len(pos_list)\n",
    "        pos_map = Counter([pos for (_,pos,_,_) in pos_list])\n",
    "        \n",
    "        pos_features = []\n",
    "        for tag in tagset:\n",
    "            bin_feat = 1 if pos_map[tag] > 0 else 0\n",
    "            bound_freq_feat = 2 if pos_map[tag] > 1 else pos_map[tag]\n",
    "            unbound_freq_feat = pos_map[tag]\n",
    "            perc_feat = pos_map[tag] / num_tokens\n",
    "            \n",
    "            pos_features.append(bin_feat)\n",
    "            pos_features.append(bound_freq_feat)\n",
    "            pos_features.append(unbound_freq_feat)\n",
    "            pos_features.append(perc_feat)\n",
    "            \n",
    "            \n",
    "        #verb_tenses = [pos for (_,pos,_) in pos_list]]\n",
    "            \n",
    "        num_ents = len(ents_list)\n",
    "        bin_ents = 1 if num_ents > 0 else 0\n",
    "        num_tokens_ents = len([ent_type for (_,_,_,ent_type) in pos_list])\n",
    "        #freq_tokens_ents = no clue\n",
    "            \n",
    "        ent_features = [bin_ents, num_ents, num_tokens_ents]\n",
    "        \n",
    "        syn_features.append(pos_features + ent_features)\n",
    "    \n",
    "    return syn_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature ablation + Experimental setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_df = pd.read_csv('data/training.txt', sep='\\t', quotechar='~')\n",
    "test_df = pd.read_csv('data/test.txt', sep='\\t', quotechar='~')\n",
    "\n",
    "training_true_labels = np.array(training_df['Label'])\n",
    "training_tweets = np.array(training_df['Tweet text'])\n",
    "\n",
    "test_true_labels = np.array(test_df['Label'])\n",
    "test_tweets = np.array(test_df['Tweet text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load features for training and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Semantical_features\n",
    "\n",
    "#train_lex_features =\n",
    "train_syn_features = get_syntactic_features(training_tweets)\n",
    "#train_sen_features =\n",
    "train_sem_feature = get_semantical_features(training_tweets)\n",
    "\n",
    "len(train_syn_features)\n",
    "\n",
    "#test_lex_features =\n",
    "test_syn_features = get_syntactic_features(test_tweets)\n",
    "#test_sen_features =\n",
    "test_sem_feature = get_semantical_features(test_tweets)\n",
    "\n",
    "training_feature_dict = {'Syntactic': train_syn_features}\n",
    "test_feature_dict = {'Syntactic': test_syn_features}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate parameter grid for grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "power = -15\n",
    "gamma_values = list()\n",
    "while power <= 3:\n",
    "    gamma = 2**power\n",
    "    gamma_values.append(gamma)\n",
    "    power += 2 \n",
    " \n",
    "power = -5\n",
    "c_values = list()\n",
    "while power <= 15:\n",
    "    c = 2**power\n",
    "    c_values.append(c)\n",
    "    power += 2\n",
    "    \n",
    "param_grid = {'C': c_values, 'gamma': gamma_values,'kernel': ['rbf']}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy', 'F1-score': 'f1', 'Recall': 'recall', 'Precision': 'precision'}\n",
    "\n",
    "for key in training_feature_dict.keys():\n",
    "    \n",
    "    training_features = training_feature_dict[key]\n",
    "    test_features = test_feature_dict[key]\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, scoring=scoring, refit='Accuracy', verbose=10)\n",
    "    grid.fit(training_features, training_true_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = grid.best_estimator_.predict(test_features)\n",
    "len(predictions)\n",
    "\n",
    "accuracy_score(test_true_labels, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = grid.best_estimator_.predict(test_features)\n",
    "len(predictions)\n",
    "\n",
    "accuracy_score(test_true_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}